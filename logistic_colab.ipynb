{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_colab",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonicchomp/Logstic/blob/master/logistic_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-jZ83CcbKaX",
        "colab_type": "code",
        "outputId": "c914cab9-5281-4556-eb38-9cb75bf63702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQj8lKzqbXG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import OrderedDict\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAjWgktAbfjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer(object):\n",
        "  def __init__(self,params=None):\n",
        "    if params is None:\n",
        "      return NotImplementedError()\n",
        "    self.params = params\n",
        "  def updates(self,loss=None):\n",
        "    if loss is None:\n",
        "      return NotImplementedError()\n",
        "    self.updates = OrderedDict()\n",
        "    self.gparams = [T.grad(loss,param) for param in self.params]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quEMGIOBbjR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SGD(Optimizer):\n",
        "    def __init__(self, learning_rate=0.01, params=None):\n",
        "        super(SGD, self).__init__(params=params)\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "    def updates(self, loss=None):\n",
        "        super(SGD, self).updates(loss=loss)\n",
        "\n",
        "        for param, gparam in zip(self.params, self.gparams):\n",
        "            self.updates[param] = param - self.learning_rate * gparam\n",
        "\n",
        "        return self.updates\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caODwju1btNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X,y,lambd, w_init):\n",
        "  X = T.matrix(name=\"X\")\n",
        "  y = T.vector(name=\"y\")  \n",
        "  w = theano.shared(w_init, name=\"w\")\n",
        "  \n",
        "  p_1 = 1/(1+T.exp(-T.dot(X,w)))\n",
        "  xent = -y * T.log(p_1) - (1-y)*T.log(1-p_1)\n",
        "  loss = xent.mean() + lambd * (w ** 2).sum()/2\n",
        "\n",
        "  params = [w]\n",
        "  updates = SGD(params=params).updates(loss)\n",
        "\n",
        "  print('start: compile model')\n",
        "\n",
        "  train = theano.function(\n",
        "            inputs=[X, y],\n",
        "            outputs=[loss,w],\n",
        "            updates=updates)\n",
        "\n",
        "  print('complete: compile model')\n",
        "\n",
        "  return train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD4xQ4GgPf_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(X,y,lambd,w):\n",
        "    X = T.matrix(name=\"X\")\n",
        "    y = T.vector(name=\"y\")\n",
        "    w = theano.shared(w, name=\"w\")\n",
        "\n",
        "    p_1 = 1/(1+T.exp(-T.dot(X,w)))\n",
        "    xent = -y * T.log(p_1) - (1-y)*T.log(1-p_1)\n",
        "    loss = xent.mean() + lambd * (w ** 2).sum()/2\n",
        "\n",
        "    \n",
        "    prediction = p_1 > 0.5\n",
        "\n",
        "    print(\"start: compile model\")\n",
        "    test = theano.function(\n",
        "        inputs = [X,y],\n",
        "        outputs = [loss,prediction]\n",
        "    )\n",
        "    print('complete: compile model')\n",
        "    return test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09BARwgsndC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class confusion_matrix(object):\n",
        "    def __init__(self,prediction,true_label):\n",
        "        self.predictions = prediction\n",
        "        self.true_label = true_label\n",
        "        self.tp = 0\n",
        "        self.TP()\n",
        "        self.tn = 0\n",
        "        self.TN()\n",
        "        self.fp = 0\n",
        "        self.FP()\n",
        "        self.fn = 0\n",
        "        self.FN()\n",
        "\n",
        "    def TP(self):\n",
        "        for pred, true in zip(self.predictions, self.true_label):\n",
        "            if pred == True and true == 1:\n",
        "                self.tp += 1\n",
        "    def TN(self):\n",
        "        for pred, true in zip(self.predictions, self.true_label):\n",
        "            if pred == False and true == 0:\n",
        "                self.tn += 1\n",
        "\n",
        "    def FP(self):\n",
        "        for pred, true in zip(self.predictions, self.true_label):\n",
        "            if pred == True and true == 0:\n",
        "                self.fp += 1\n",
        "\n",
        "    def FN(self):\n",
        "        for pred, true in zip(self.predictions, self.true_label):\n",
        "            if pred == False and true == 1:\n",
        "                self.fn += 1\n",
        "    \n",
        "    def accuracy(self):\n",
        "        return (self.tp+self.tn) / (self.tp+self.tn+self.fp+self.fn)\n",
        "\n",
        "    def error(self):\n",
        "        return 1 - accu()\n",
        "\n",
        "    def precision(self):\n",
        "        return self.tp /(self.tp + self.fp)\n",
        "\n",
        "    def recall(self):\n",
        "        return self.tp /(self.tp + self.fn)\n",
        "    \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnaK4N_ybeM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    breast_cancer = '/content/drive/My Drive/ロジスティック回帰/duke-breast-cancer.txt'\n",
        "    data = pd.read_table(breast_cancer,header=None)\n",
        "    X = data.drop(data.columns[0],axis=1)\n",
        "    y = data[data.columns[0]]\n",
        "\n",
        "    X_train, X_test, y_train, y_test=train_test_split(X, y, shuffle=True)\n",
        "    \n",
        "    lambd= 0.01\n",
        "    training_epochs = 10\n",
        "    np.random.seed(seed=38)\n",
        "    w_init = np.random.normal(loc=0.0,scale=lambd,size=X_train.shape[1])\n",
        "    train = model(X_train, y_train, lambd, w_init)\n",
        "\n",
        "    min_w = np.empty_like(w_init)\n",
        "    min_loss = 999\n",
        "    print(\"epochs: {}\".format(training_epochs))\n",
        "    \n",
        "    for t in range(training_epochs):\n",
        "        loss, w = train(X_train,y_train)\n",
        "        if t % (training_epochs/10) == 0:\n",
        "            print('{}: loss:{}'.format(t,loss))\n",
        "        if loss < min_loss :\n",
        "            min_w = w\n",
        "            min_loss = loss\n",
        "\n",
        "    print(\"-\"*20)\n",
        "    test = test_model(X_test,y_test,lambd,min_w)\n",
        "    test_loss, prediction = test(X_test,y_test)\n",
        "    print(\"test loss: {}\".format(test_loss))      \n",
        "    cm = confusion_matrix(prediction, y_test) \n",
        "    print(\"Accuracy: {}\".format(cm.accuracy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh8Zz2eCbk_f",
        "colab_type": "code",
        "outputId": "287c00c2-bdfd-403e-8f0b-133c71e9c4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start: compile model\n",
            "complete: compile model\n",
            "epochs: 10\n",
            "0: loss:0.6819969058338851\n",
            "1: loss:0.36497589066659447\n",
            "2: loss:0.5423279054020109\n",
            "3: loss:0.637281733491918\n",
            "4: loss:0.19097024089898795\n",
            "5: loss:0.0957232419571012\n",
            "6: loss:0.07492028781569349\n",
            "7: loss:0.06846651689312289\n",
            "8: loss:0.06320234599524963\n",
            "9: loss:0.05879130951446321\n",
            "--------------------\n",
            "start: compile model\n",
            "complete: compile model\n",
            "test loss: 0.1462203133831545\n",
            "Accuracy: 0.9090909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnB-iHbe3Tqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}